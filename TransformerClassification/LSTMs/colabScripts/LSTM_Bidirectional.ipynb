{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/My Drive/LSTM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder LSTM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout, num_layers=1, bidirectional=False):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def initHidden(self, batch=1, num_layers=1):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return torch.zeros(self.num_layers * (1 + self.bidirectional), batch, self.hidden_size, device=device), torch.zeros(self.num_layers * (1 + self.bidirectional), batch, self.hidden_size, device=device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder LSTM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout, num_layers=1, bidirectional=False):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=num_layers, bidirectional=self.bidirectional)\n",
    "        self.out = nn.Linear(self.hidden_size * (1 + self.bidirectional), output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def initHidden(self, batch=1):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return torch.zeros(self.num_layers * (1 + self.bidirectional), batch, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross - Validation Fold generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from sklearn import model_selection\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence, device):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def split(pairs, lang, device):\n",
    "    train = []\n",
    "    test = []\n",
    "    for label in pairs:\n",
    "        label_tensor = tensorFromSentence(lang, label, device)\n",
    "        iters = pairs[label]\n",
    "        test_index = random.randint(0, len(iters) - 1)\n",
    "        accept_prob = random.random()\n",
    "        for i in range(len(iters)):\n",
    "            if i == test_index and len(iters) != 1 and accept_prob > 0.5:\n",
    "                test.append([iters[i], label_tensor])\n",
    "            else:\n",
    "                train.append([iters[i], label_tensor])\n",
    "    return train, test\n",
    "\n",
    "def kfoldSplit(pairs, lang, device, split=10):\n",
    "    folds = []\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for label in pairs:\n",
    "        for iter in pairs[label]:\n",
    "            inputs.append(iter)\n",
    "            outputs.append(label)\n",
    "    \n",
    "    skf = model_selection.StratifiedKFold(n_splits=split, shuffle=True)\n",
    "    indices = skf.split(inputs, outputs)\n",
    "\n",
    "    for train_indices, test_indices in indices:\n",
    "        curr_train = []\n",
    "        curr_test = []\n",
    "        for indices in train_indices:\n",
    "            curr_train.append([inputs[indices], tensorFromSentence(lang,  outputs[indices], device)])\n",
    "        for indices in test_indices:\n",
    "            curr_test.append([inputs[indices], tensorFromSentence(lang,  outputs[indices], device)])\n",
    "        folds.append([curr_train, curr_test])\n",
    "    \n",
    "    return folds\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy calculator and result documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, output_lang, sil0, sil1, max_length=470):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence\n",
    "        input_length = len(sentence)\n",
    "        encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden, encoder_cell)\n",
    "\n",
    "        decoder_input = torch.tensor([[sil0]], device=device)\n",
    "\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "        \n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == sil1:\n",
    "                decoded_words.append('sil1')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "\n",
    "def calculateTrainingAccuracy(encoder, decoder, pairs, output_lang, sil0, sil1, file_name=None, write = True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    results = None\n",
    "    if write:\n",
    "        results = open(file_name, 'w')\n",
    "    for pair in pairs:\n",
    "        output_words = evaluate(encoder, decoder, pair[0], output_lang, sil0, sil1)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        sent = [output_lang.index2word[i.item()] for i in pair[1]]\n",
    "        true_sentence = ' '.join(sent)\n",
    "        if write:\n",
    "            print('Predicted Sentence: ', output_sentence, file=results)\n",
    "            print('True Sentence: ' , true_sentence, file=results)\n",
    "        answer = None\n",
    "        if output_sentence == true_sentence:\n",
    "            correct += 1\n",
    "            answer = \"CORRECT\"\n",
    "        else:\n",
    "            answer = \"INCORRECT\"\n",
    "        total += 1\n",
    "        if write:\n",
    "            print('Result: ', answer, file=results)\n",
    "    if write:\n",
    "        print('Recognition Total: ', str(correct/total), file=results)\n",
    "        results.close()\n",
    "    return correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random \n",
    "import time\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, sil0, sil1):\n",
    "    encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = len(input_tensor)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        _, encoder_hidden, encoder_cell = encoder(\n",
    "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
    "\n",
    "    decoder_input = torch.tensor([[sil0]], device=device)\n",
    "\n",
    "    decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == sil1:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def testSetLoss(encoder, decoder, input_tensor, target_tensor, criterion, sil0, sil1):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_tensor\n",
    "        input_length = len(input_tensor)\n",
    "        target_length = target_tensor.size(0)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden, encoder_cell)\n",
    "\n",
    "        decoder_input = torch.tensor([[sil0]], device=device)\n",
    "\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_cell)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if topi.item() == sil1:\n",
    "                break\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return loss.item() / target_length\n",
    "\n",
    "def trainIters(encoder, decoder, epochs, train_set, test_set, sil0, sil1, output_lang, lr=1e-4, lr_decay=1, lr_drop_epoch=10, l2_penalty = 0):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    test_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr, weight_decay = l2_penalty)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr, weight_decay = l2_penalty)\n",
    "\n",
    "    best_test_acc = -1\n",
    "    best_encoder = None\n",
    "    best_decoder = None\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    drop = True\n",
    "    for iter in range(1, epochs + 1):\n",
    "        if drop:\n",
    "            if iter == lr_drop_epoch:\n",
    "                encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr * (lr_decay)**(iter), weight_decay = l2_penalty)\n",
    "                decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr * (lr_decay)**(iter), weight_decay = l2_penalty)\n",
    "        else:\n",
    "            encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr * (lr_decay), weight_decay = l2_penalty)\n",
    "            decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr * (lr_decay), weight_decay = l2_penalty)\n",
    "\n",
    "        for pairs in train_set:\n",
    "            input_tensor = pairs[0]\n",
    "            target_tensor = pairs[1]\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                        decoder, encoder_optimizer, decoder_optimizer, criterion, sil0, sil1)\n",
    "            print_loss_total += loss\n",
    "\n",
    "        for pair in test_set:\n",
    "            input_tensor = pair[0]\n",
    "            target_tensor = pair[1]\n",
    "            test_loss_total += testSetLoss(encoder, decoder, input_tensor, target_tensor, criterion, sil0, sil1)\n",
    "\n",
    "        print_loss_avg = print_loss_total / len(train_set)\n",
    "        test_loss_avg = test_loss_total / len(test_set)\n",
    "        print_loss_total = 0\n",
    "        test_loss_total = 0\n",
    "        test_acc = calculateTrainingAccuracy(encoder, decoder, test_set, output_lang, sil0, sil1, write=False)\n",
    "        train_acc = calculateTrainingAccuracy(encoder, decoder, train_set, output_lang, sil0, sil1, write=False)\n",
    "        print('%s (%d %d%%) train loss: %.4f train acc: %.4f test loss: %.4f test acc: %.4f' % (timeSince(start, iter / epochs),\n",
    "                                        iter, iter / epochs * 100, print_loss_avg, train_acc, test_loss_avg, test_acc))\n",
    "        \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_encoder = copy.deepcopy(encoder)\n",
    "            best_decoder = copy.deepcopy(decoder)\n",
    "\n",
    "        plot_losses.append(test_loss_avg)\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return best_encoder, best_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main script - uses above files to run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import random\n",
    "\n",
    "#########    HYPERPARAMETERS   ############\n",
    "random.seed(42)\n",
    "users = [\"p1\"]\n",
    "file_name = \"p1\"\n",
    "num_features = 0\n",
    "hidden_size = 1500\n",
    "epochs = 60\n",
    "limit_features = False\n",
    "lr = 1e-4\n",
    "lr_decay = 0.95\n",
    "lr_drop = 20\n",
    "dropout = 0.5\n",
    "num_layers = 1\n",
    "k_fold = False\n",
    "folds = 5\n",
    "bidirectional = True\n",
    "expansion_factor = 1\n",
    "l2_penalty = 0\n",
    "###########################################\n",
    "\n",
    "sil0 = 0\n",
    "sil1 = 0\n",
    "\n",
    "def expand(dataset_as_array, factor):\n",
    "    expanded_array = []\n",
    "    for pair in dataset_as_array:\n",
    "        content = pair[0]\n",
    "        label = pair[1]\n",
    "\n",
    "        expanded_pair = [[[],label] for i in range(factor)]\n",
    "        for frame in range(len(content)):\n",
    "            expanded_pair[frame % factor][0].append(content[frame])\n",
    "        expanded_array.extend(expanded_pair)\n",
    "    return expanded_array\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "eng = Lang(\"english\")\n",
    "pairs = {}\n",
    "print(\"Reading data from files...\")\n",
    "for user in users:\n",
    "    for file in glob.glob(\"data/\"+user+\"/*.ark\"):\n",
    "        label = \"sil0_\"+file.split(\".\")[1]+\"_sil1\"\n",
    "        label = label.replace(\"_\", \" \")\n",
    "        eng.addSentence(label)\n",
    "\n",
    "        sil0 = eng.word2index[\"sil0\"]\n",
    "        sil1 = eng.word2index[\"sil1\"]\n",
    "        content = []\n",
    "        f = open(file)\n",
    "        for x in f:\n",
    "            line = x\n",
    "            if \"[\" in x:\n",
    "                line = x.split(\"[ \")[1]\n",
    "            elif \"]\" in x:\n",
    "                line = x.split(\"]\")[0]\n",
    "            features = []\n",
    "            line = line.strip(\"\\n\").split(\" \")\n",
    "            if limit_features:\n",
    "                line = line[-num_features:]\n",
    "            for f in line:\n",
    "                try:\n",
    "                    features.append(float(f)*1000)\n",
    "                except:\n",
    "                    pass\n",
    "            if len(features) != 0:\n",
    "                num_features = len(features)\n",
    "                content.append(torch.tensor(features, dtype=torch.float, device=device).view(1, 1, -1))\n",
    "        if label in pairs:\n",
    "            temp = pairs[label]\n",
    "            temp.append(content)\n",
    "            pairs[label] = temp\n",
    "        else:\n",
    "            pairs[label] = [content]\n",
    "for label in pairs:\n",
    "    print(\"Label = \" + label + \" Number of iterations = \" + str(len(pairs[label])))\n",
    "if not k_fold:    \n",
    "    print(\"Splitting data into train and test...\")\n",
    "    train_set, test_set = split(pairs, eng, device)\n",
    "    train_set, test_set = expand(train_set, expansion_factor), expand(test_set, expansion_factor)\n",
    "    encoder = EncoderLSTM(num_features, hidden_size, dropout, num_layers=num_layers, bidirectional=bidirectional).to(device)\n",
    "    decoder = DecoderLSTM(hidden_size, eng.n_words, dropout, num_layers=num_layers, bidirectional=bidirectional).to(device)\n",
    "    print(\"Split done. Elements in train: %d and elements in test: %d. Starting training...\" % (len(train_set), len(test_set)))\n",
    "    best_encoder, best_decoder = trainIters(encoder, decoder, epochs, train_set, test_set, sil0, sil1, eng, lr=lr, lr_decay=lr_decay, lr_drop_epoch=lr_drop, l2_penalty=l2_penalty)\n",
    "    print(\"Training done. Printing stats to file....\")\n",
    "    calculateTrainingAccuracy(best_encoder, best_decoder, test_set, eng, sil0, sil1, 'results/'+file_name+'/results.txt')\n",
    "    print(\"Saving Models\")\n",
    "    torch.save(best_encoder.state_dict(), \"models/\"+file_name+\"/encoderLSTM.pt\")\n",
    "    torch.save(best_decoder.state_dict(), \"models/\"+file_name+\"/decoderLSTM.pt\")\n",
    "\n",
    "else:\n",
    "    print(\"Generating folds...\")\n",
    "    trainTestFolds = kfoldSplit(pairs, eng, device, split=folds)\n",
    "    print(\"Fold generation done...\")\n",
    "    fold_num = 1\n",
    "    for curr_fold in trainTestFolds:\n",
    "        encoder = EncoderLSTM(num_features, hidden_size, dropout, num_layers=num_layers, bidirectional=bidirectional).to(device)\n",
    "        decoder = DecoderLSTM(hidden_size, eng.n_words, dropout, num_layers=num_layers, bidirectional=bidirectional).to(device)\n",
    "        print(\"Starting training on fold %d. %d elements in curr_fold[0] and %d in curr_fold[1]\" % (fold_num, len(curr_fold[0]), len(curr_fold[1])))\n",
    "        best_encoder, best_decoder = trainIters(encoder, decoder, epochs, curr_fold[0], curr_fold[1], sil0, sil1, eng, lr=lr, lr_decay=lr_decay, lr_drop_epoch=lr_drop, l2_penalty=l2_penalty)\n",
    "        print(\"Training done. Saving predictions to file...\")\n",
    "        calculateTrainingAccuracy(best_encoder, best_decoder, curr_fold[1], eng, sil0, sil1, 'results/'+file_name+'/results_fold'+str(fold_num)+'.txt')\n",
    "        print(\"Saving Models\")\n",
    "        torch.save(best_encoder.state_dict(), \"models/\"+file_name+\"/encoderLSTM_fold\"+str(fold_num)+\".pt\")\n",
    "        torch.save(best_decoder.state_dict(), \"models/\"+file_name+\"/decoderLSTM_fold\"+str(fold_num)+\".pt\")\n",
    "        fold_num += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CopyCat_LSTM_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
